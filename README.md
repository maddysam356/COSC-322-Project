# COSC-322-Project
This is the repository for the COSC 322 Project: The game of the Amazons

Detailed Task List for Game of the Amazons Project

1. Initial Setup

Maddy and Mac: Server Communication Setup (Completed)

Download and set up the provided Maven project.

Ensure all dependencies are correctly installed.

Run initial server connection tests with COSC322Test.java.

Debug connection issues and ensure stable communication with the game server.

Game Rules and Move Generation (TODO)

Study the Game of the Amazons rules.

Implement move validation to ensure all moves are legal.

Develop a function to generate all possible legal moves.

Optimize move generation for efficiency.

AI Algorithm Research

Study heuristic evaluation functions, including the min-distance heuristic.

Research Minimax with Alpha-Beta Pruning and Monte Carlo Tree Search (MCTS).

Decide on which algorithm to implement: Minimax with Alpha-Beta Pruning or Monte Carlo Tree Search.

Begin initial implementation of the chosen algorithm.

Optimize AIâ€™s search depth and execution speed.

Maddy: Documentation & Report Writing

Create project documentation to track team progress.

Start writing the project introduction and methodology.

Maintain a log of challenges and solutions encountered.

2. Mid-Project Development

Server Message Handling

Implement functions to process game updates from the server.

Ensure smooth exchange of messages between the server and AI.

Handle game start, move updates, and game-end notifications.

Heuristic Evaluation Functions

Implement min-distance heuristic.

Develop additional evaluation functions (optional):

Mobility heuristic (evaluating available moves).

Board control heuristic (strategic positioning).

Optimize heuristic calculations for efficiency.

AI Optimization & Move Selection

Fine-tune heuristic evaluation weights for better AI performance.

Test AI in different board positions to improve decision-making.

Full System Testing

Conduct end-to-end tests covering AI and server communication.

Run simulated tournament matches to test AI performance.

Identify and fix any bugs in server communication or AI.

Progress Report & Documentation

Write the mid-project progress report.

Develop test cases for move validation and AI evaluation.

Ensure all project components are well-documented.

3. Final Development & Integration

AI Testing & Validation

Perform large-scale simulations to refine AI strategies.

Ensure AI stability during long matches.

Full System Debugging

Identify and fix final bugs or performance issues.

Conduct stress tests to ensure stability in tournament settings.

Final Report & Submission

Complete final project report, including methodology, results, and reflections.

Prepare a presentation/ demonstration for the tournament.

Ensure all code is documented and formatted properly.

4. Tournament Preparation & Final Debugging

Conduct test matches against other teams.

Finalize AI strategy based on testing results.

Ensure project components are seamlessly integrated.

Submit final code, documentation, and report.

